<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.3 Prädiktoren definieren | Mixed Models</title>
  <meta name="description" content="2.3 Prädiktoren definieren | Mixed Models" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="2.3 Prädiktoren definieren | Mixed Models" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.3 Prädiktoren definieren | Mixed Models" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="von-averaging-zur-regression.html">
<link rel="next" href="kollinearitat.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="first-things-first.html"><a href="first-things-first.html"><i class="fa fa-check"></i><b>1</b> First Things First</a><ul>
<li class="chapter" data-level="1.1" data-path="uberblick.html"><a href="uberblick.html"><i class="fa fa-check"></i><b>1.1</b> Überblick</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="exkurs-regressionen.html"><a href="exkurs-regressionen.html"><i class="fa fa-check"></i><b>2</b> Exkurs Regressionen</a><ul>
<li class="chapter" data-level="2.1" data-path="averaging-ist-eine-least-squares-regression.html"><a href="averaging-ist-eine-least-squares-regression.html"><i class="fa fa-check"></i><b>2.1</b> Averaging ist eine Least-Squares Regression</a></li>
<li class="chapter" data-level="2.2" data-path="von-averaging-zur-regression.html"><a href="von-averaging-zur-regression.html"><i class="fa fa-check"></i><b>2.2</b> Von Averaging zur Regression</a></li>
<li class="chapter" data-level="2.3" data-path="pradiktoren-definieren.html"><a href="pradiktoren-definieren.html"><i class="fa fa-check"></i><b>2.3</b> Prädiktoren definieren</a></li>
<li class="chapter" data-level="2.4" data-path="kollinearitat.html"><a href="kollinearitat.html"><i class="fa fa-check"></i><b>2.4</b> Kollinearität</a></li>
<li class="chapter" data-level="2.5" data-path="codinginr.html"><a href="codinginr.html"><i class="fa fa-check"></i><b>2.5</b> Variablenkodierung in R</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="random-intercept-models.html"><a href="random-intercept-models.html"><i class="fa fa-check"></i><b>3</b> Random intercept models</a><ul>
<li class="chapter" data-level="3.1" data-path="generelle-logik.html"><a href="generelle-logik.html"><i class="fa fa-check"></i><b>3.1</b> Generelle Logik</a></li>
<li class="chapter" data-level="3.2" data-path="in-r.html"><a href="in-r.html"><i class="fa fa-check"></i><b>3.2</b> in R</a></li>
<li class="chapter" data-level="3.3" data-path="simulationen.html"><a href="simulationen.html"><i class="fa fa-check"></i><b>3.3</b> Simulationen</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="randomslopes.html"><a href="randomslopes.html"><i class="fa fa-check"></i><b>4</b> Random slope models</a><ul>
<li class="chapter" data-level="4.1" data-path="mixed-models-vs-einzelne-regressionen.html"><a href="mixed-models-vs-einzelne-regressionen.html"><i class="fa fa-check"></i><b>4.1</b> Mixed Models vs. einzelne Regressionen</a></li>
<li class="chapter" data-level="4.2" data-path="simulationen-1.html"><a href="simulationen-1.html"><i class="fa fa-check"></i><b>4.2</b> Simulationen</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referenzen.html"><a href="referenzen.html"><i class="fa fa-check"></i>Referenzen</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mixed Models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pradiktoren-definieren" class="section level2">
<h2><span class="header-section-number">2.3</span> Prädiktoren definieren</h2>
<div id="beispielexperiment" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Beispielexperiment</h3>
<p>Beispiel ist hier ein Sprachverständnisexperiment, in dem ein Kontext Erwartungen bei den Teilnehmern für ein bestimmtes Wort, <em>a</em> oder <em>an</em>, generiert. Siehe: <em>The day was breezy so the boy went outside to fly (<strong>a</strong> kite/<strong>an</strong> airplane)</em>. Wir haben also eine kategorische Kovariate (Wort: <em>a</em> vs. <em>an</em>) und eine kontinuierliche Kovariate: Die Erwartung des Wortes, die zwischen 0 und 1 liegt.</p>
</div>
<div id="das-traditionelle-erp-als-intercept" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Das traditionelle ERP als Intercept</h3>
<p>Angenommen, wir haben einen einzigen Prädiktor: <span class="math inline">\(x_{1i} = 1\)</span></p>
<p>In der Sprache linearer Regressionen ist dieser Prädiktor ein Intercept. Unsere Regressionsgleichung ist dann:</p>
<p><span class="math display">\[
y_{i}=\beta_{1} x_{1 i}+\textrm{ noise }_{i}=\beta_{1}+\textrm{ noise }_{i}
\]</span></p>
<p>Wie oben: Wenn wir die Least-Squares-Lösung finden, ist <span class="math inline">\(\beta_{1}\)</span> gleich der Mittelwert aller <span class="math inline">\(y_i\)</span>-Werte.</p>
<div class="figure"><span id="fig:unnamed-chunk-3"></span>
<img src="pics/smith_a_fig1_1.jpg" alt="Separate Modelle für a- und an-Trials." width="1560" />
<p class="caption">
Figure 2.1: Separate Modelle für a- und an-Trials.
</p>
</div>
<p>Die Ergebnisse stimmen mit denen des Mittelns überein, aber sind ein wenig nervig zu ermitteln: Bei kategorischen Faktoren über mehrere Stufen müssen wir mehrere Modelle fitten, hier zwei: Eins für <em>a</em>-Trials, eins für <em>an</em>-Trials.</p>
</div>
<div id="multiple-erps-via-dummy-coding" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Multiple ERPs via Dummy-Coding</h3>
<p>Anstatt mehrere Modelle zu fitten, können wir auch beide ERPs gleichzeitig mit einem einzelnen Modell schätzen, indem wir Dummy-Coding als Trick verwenden - der Standardweg, um kategorische Daten in einem Regressionsmodell anzupacken.</p>
<ul>
<li><span style=" font-weight: bold;    color: #E8793A !important;">Siehe:</span> “This is the default method of coding categorical variables used by SAS, and is also used by default by <code>R</code> for models that do not contain an intercept term.”
<ul>
<li><span style=" font-weight: bold;    color: #E8793A !important;">TO DO:</span> Modelle ohne Intercept in <code>R</code> nachschlagen und schauen, was da passiert?</li>
</ul></li>
</ul>
<p><span class="math display">\[
x_{1 i}=\left\{\begin{array}{ll}{1,} &amp; {\text { if stimulus } i \text { is a}} \\ {0,} &amp; {\text { if stimulus } i \text { is an }}\end{array} \quad x_{2 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \text { is a}} \\ {1,} &amp; {\text { if stimulus } i \text { is an }}\end{array}\right.\right.
\]</span></p>
<p><span style=" font-weight: bold;    color: #6BBFA6 !important;">Fand ich erst etwas verwirrend:</span> Im Paper steht vor beiden Klammern <span class="math inline">\(x_{1i}\)</span>, aber das ergibt für mich keinen Sinn wenn ich mir die entsprechende Grafik dazu, das Einsetzen in die Formel und spätere Gleichungen anschaue … ?</p>
<p>Wenn wir das in die Regressionsgleichung packen …</p>
<p><span class="math display">\[
y_{i}=\beta_{1} x_{1 i}+\beta_{2} x_{2 i}+\textrm{noise}_{i}
\]</span></p>
<p>dann wird Least-Squares-Fitting dafür sorgen, dass <span class="math inline">\(\beta_{1}\)</span> dem Mittel aller <em>a</em>-Trials entspricht, und <span class="math inline">\(\beta_{2}\)</span> dem Mittel aller <em>an</em>-Trials.</p>
<div class="figure"><span id="fig:unnamed-chunk-4"></span>
<img src="pics/smith_a_fig1_2.jpg" alt="Dummy-Coding, um die Modelle für a- und an-Trials zu kombinieren." width="1560" />
<p class="caption">
Figure 2.2: Dummy-Coding, um die Modelle für a- und an-Trials zu kombinieren.
</p>
</div>
<p>Denn: Wenn wir in einem Trial <em>i</em> das Wort <em>a</em> präsentiert haben, ist <span class="math inline">\(x_{1i} =\)</span> 1 und <span class="math inline">\(x_{2i} =\)</span> 0, was bedeutet:</p>
<p><span class="math display">\[
y_{i}=\beta_{1} \times 1+\beta_{2} \times 0+\textrm{noise}_{i}=\beta_{1}+\textrm{noise}_{i}
\]</span></p>
<p>Und wenn wir in einem Trial <em>i</em> das Wort <em>an</em> gezeigt haben, ist <span class="math inline">\(x_{1i} =\)</span> 0 und <span class="math inline">\(x_{2i} =\)</span> 1, was bedeutet:</p>
<p><span class="math display">\[
y_{i}=\beta_{1} \times 0+\beta_{2} \times 1+\textrm{noise}_{i}=\beta_{2}+\textrm{noise}_{i}
\]</span></p>
<p>Letztendlich <span style=" font-weight: bold;    color: #6BBFA6 !important;">fitten wir also zwei Versionen unseres Intercept-Only-Models</span> auf verschiedene Subsets der Daten. Der einzige Unterschied ist, dass wir vorher die Daten explizit aufgeteilt haben; jetzt definieren wir unsere <span class="math inline">\(x\)</span>e und der Split der Daten passiert automatisch als Ergebnis des Least-Squares-Fitting-Prozesses. Eine allgemeine Variante des “Zero-Tricks” kann genutzt werden, um arbiträre Regressionsmodelle in einen einzigen Fit zu kombinieren, was für verschiedene Zwecke nützlich sein kann.</p>
</div>
<div id="treatmentcoding" class="section level3">
<h3><span class="header-section-number">2.3.4</span> Unterschieds-ERPs via Treament-Coding</h3>
<p>Gängigerer Ansatz, um kategoriale Variablen in Regressionen zu händeln: <span style=" font-weight: bold;    color: #E8793A !important;">Treatment-Coding</span>, d.h. <span style=" font-weight: bold;    color: #6BBFA6 !important;">Dummy-Coding für alle Level eines Faktors - bis auf eins</span> und dann einen <span style=" font-weight: bold;    color: #6BBFA6 !important;">Intercept-Term</span> hinzufügen. (Das Level, das ausgelassen wird, heißt <span style=" font-weight: bold;    color: #6BBFA6 !important;">Referenzlevel</span>.)</p>
<p>Wenn z.B. der <em>a</em>-Stimulus das Referenzlevel ist:</p>
<p><span class="math display">\[
x_{1 i}=1, \quad x_{2 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \textrm{ is a}} \\ {1,} &amp; {\textrm{ if stimulus } i \textrm{ is an }}\end{array}\right.
\]</span></p>
<p>Mit diesem Kodierungsschema spiegelt <span class="math inline">\(\beta_{1}\)</span> nach Least-Squares-Fitting den Mittelwert für <em>a</em>-Trials wider (also das Intercept für <em>a</em>!) und <span class="math inline">\(\beta_{2}\)</span> den <span style=" font-weight: bold;    color: #6BBFA6 !important;">Unterschied zwischen <em>an</em>-Trials und <em>a</em>-Trials</span> (wie viel ich zum/vom Intercept für <em>a</em> hinzufügen/abziehen muss, um beim Intercept für <em>an</em> zu landen), d.h., <span class="math inline">\(\beta_{2}\)</span> ergibt das Differenz-ERP.</p>
<ul>
<li><span style=" font-weight: bold;    color: #E8793A !important;">Note:</span> “This is the default method of coding categorical variables in <code>R</code> and SPSS.”
<ul>
<li><span style=" font-weight: bold;    color: #E8793A !important;">Data coding in R:</span> Siehe dazu den <a href="codinginr.html#codinginr">Abschnitt</a></li>
</ul></li>
</ul>
<div class="figure"><span id="fig:unnamed-chunk-5"></span>
<img src="pics/smith_a_fig1_3.jpg" alt="Treatment-Coding, um die Modelle für a- und an-Trials zu kombinieren." width="1560" />
<p class="caption">
Figure 2.3: Treatment-Coding, um die Modelle für a- und an-Trials zu kombinieren.
</p>
</div>
<p>Das ist der Grund, warum es <span style=" font-weight: bold;    color: #E8793A !important;">Treatment-Coding</span> heißt: Wenn die Kontrollgruppe das Referenzlevel ist und man verschiedene “Treatments” hinzufügt, zeigt das resultierende <span class="math inline">\(\beta\)</span> inwiefern diese “Treatments” das Outcome im Vergleich zur Kontrolle verändern.</p>
<p><span style=" font-weight: bold;    color: #E8793A !important;">Wichtig:</span> Die gefitteten Werte für <span class="math inline">\(\beta_j\)</span> hängen nicht nur davon ab, wie der <span class="math inline">\(j\)</span>te Prädiktor definiert ist, sondern wie <span style=" font-weight: bold;    color: #6BBFA6 !important;">alle</span> Prädiktoren <span class="math inline">\(x_{1i}, ..., x_{ni}\)</span> definiert sind. Von Beispiel b) zu c) hat sich lediglich die Definition <span class="math inline">\(x_{1i}\)</span> verändert, aber es war die Interpretation von <span class="math inline">\(\beta_2\)</span>, die sich verändert hat (während <span class="math inline">\(\beta_1\)</span> gleich geblieben ist).</p>
<p><span class="citation">Smith &amp; Kutas (2015)</span> beschreiben das sehr schön: Der Least-Squares-Fitting-Prozess interessiert sich nicht direkt für die <span class="math inline">\(\beta\)</span>-Werte, sondern nur für die predicted Values (jeweils die ganz rechte Spalte in den Grafiken). Er findet die <span class="math inline">\(\beta\)</span>-Werte, die dafür sorgen, dass die predicted Values den Daten so nahe wie möglich kommen. Weil diese predicted Values aber dadurch zu Stande kommen, dass viele <span class="math inline">\(\beta\)</span>-Werte kombiniert werden, bedeutet das, dass die gewählten <span class="math inline">\(\beta\)</span>-Werte nicht diejenigen sind, die individuell am besten zu den Daten passen, sondern die, die “am effektivsten zusammenarbeiten”. Im Falle von Treatment-Coding muss <span class="math inline">\(\beta_1\)</span> alleine “arbeiten”, um zu den <em>a</em>-Stimuli zu passen, während <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_2\)</span> für <em>an</em>-Stimuli zusammenarbeiten können. Das “effizienteste Teamwork” ist dann erreicht, wenn <span class="math inline">\(\beta_1\)</span> sich darauf konzentriert, zu den <em>a</em>-Stimuli zu passen, während <span class="math inline">\(\beta_2\)</span> sich darauf konzentriert, <span class="math inline">\(\beta_1\)</span> zu korrigieren, sodass sie in Kombination zu den <em>an</em>-Stimuli passen.</p>
</div>
<div id="probleme-mit-dummycoding" class="section level3">
<h3><span class="header-section-number">2.3.5</span> Probleme mit Dummycoding</h3>
<p>Dummykodierung führt allerdings auch zu <span style=" font-weight: bold;    color: #6BBFA6 !important;">möglichen Problemen</span> für einige Kodierungsschemata, die zunächst schlüssig erscheinen: Solche, in denen <span style=" font-weight: bold;    color: #6BBFA6 !important;">mehrere Prädiktoren perfekt kolinear sind</span>, d.h., redundant.
- Wenn versehentlich derselbe Prädiktor zwei mal eingefüttert wird.
- Wenn manche Zellen aus dem Design ausgelassen werden.</p>
<p>Oder - weniger offensichtlich - wenn man das ursprüngliche Dummy-Coding-Schema gleichzeitig für zwei verschiedene Faktoren verwendet. In unserem Beispielexperiment könnte man sich vorstellen, dass die Items GROßGESCHRIEBEN präsentiert wurden. Wir könnten dann folgende dummy-kodierte Prädiktoren definieren:</p>
<p><span class="math display">\[
x_{1 i}=\left\{\begin{array}{ll}{1,} &amp; {\text { if stimulus } i \text { is a}} \\ {0,} &amp; {\text { if stimulus } i \text { is an }}\end{array} \quad x_{2 i}=\left\{\begin{array}{l}{0, \text { if stimulus } i \text { is a}} \\ {1, \text { if stimulus } i \text { is an }}\end{array}\right.\right.
\]</span></p>
<p><span class="math display">\[
x_{3 i}=\left\{\begin{array}{ll}{1,} &amp; {\text { if stimulus } i \text { is lowercase }} \\ {0,} &amp; {\text { if stimulus } i \text { is UPPERCASE }}\end{array} \quad x_{4 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \text { is lowercase }} \\ {1,} &amp; {\text { if stimulus } i \text { is UPPERCASE }}\end{array}\right.\right.
\]</span></p>
<p>Angenommen, es gibt nun eine EEG-Komponente (z.B. die N1), die über alle vier Bedingungen hinweg identisch ist. (Mit anderen Worten: Ein Outcome, das über alle vier Bedingungen hinweg denselben Wert annimmt.) Die <span class="math inline">\(\beta\)</span>s könnten nun “zusammenarbeiten” und abbilden, dass <em>a</em> und <em>an</em> beide mit der N1 zusammenhängen - wodurch wir die N1 in der EEG-Welle für <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_2\)</span> packen würden. Eine genau so gute Erklärung wäre es anzunehmen, dass die N1 durch groß geschriebene wie auch klein geschriebene Wörter ausgelöst wird, was sich in den Wellen für <span class="math inline">\(\beta_3\)</span> und <span class="math inline">\(\beta_4\)</span> widerspiegeln würde. Oder aber <em>a</em> und <em>an</em> verursachen beide einen positiven (also entgegengesetzten) Ausschlag, aber groß und klein geschriebene Wörter generieren beide ein so großes negatives Signal, dass sie diesem Effekt entgegenwirken und der Gesamteffekt negativ (N2) ist. Alle Interpretationen würden zu den Daten passen. Weil all diese <span class="math inline">\(\beta\)</span>-Kombinationen zu denselben Vorhersagen führen würden, kann Least-Squares-Fitting nicht zwischen ihnen unterscheiden. In mancher Software wird dann einfach stillschweigend und semi-arbiträr eine der Möglichkeiten ausgewählt.</p>
<p>Treatment-Coding erlaubt es allerdings, kategorische Variablen und deren Interaktionen nicht-redundant zu kodieren. In unserem Beispiel erhalten wir so:</p>
<p><span class="math display">\[
x_{1 i}=1 \quad x_{2 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \text { is a}} \\ {1,} &amp; {\text { if stimulus } i \text { is an }}\end{array}\right.
\]</span></p>
<p><span class="math display">\[
x_{3 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \text { is lowercase }} \\ {1,} &amp; {\text { if stimulus } i \text { is UPPERCASE }}\end{array} \quad x_{4 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { if stimulus } i \text { is either lowercase or a }} \\ {1,} &amp; {\text { if stimulus } i \text { is an UPPERCASE an }}\end{array}\right.\right.
\]</span></p>
<p>Sofern mit ins Modell aufgenommen, ist <span class="math inline">\(x_{4i} = x_{2i} \times x_{3i}\)</span> - die Interaktion. <span class="math inline">\(\beta_1\)</span> wird hier also das ERP für <strong>klein geschriebene</strong> <em>a</em>s, <span class="math inline">\(\beta_2\)</span> den Unterschied zwischen <strong>klein geschriebenen</strong> <em>a</em>s und <strong>klein geschriebenen</strong> <em>an</em>s, <span class="math inline">\(\beta_3\)</span> den Unterschied zwischen <strong>klein geschriebenen</strong> <em>a</em>s und <strong>groß geschriebenen</strong> <em>A</em>s - und <span class="math inline">\(\beta_4\)</span> den <span style=" font-weight: bold;    color: #E8793A !important;">Unterschied der Unterschiede</span> abbilden: Wenn wir erst den Unterschied zwischen <strong>groß geschriebenen</strong> <em>AN</em>s und <strong>groß geschriebenen</strong> <em>A</em>s berechnen und dann den Unterschied zwischen <strong>klein geschriebenen</strong> <em>an</em>s und <strong>klein geschriebenen</strong> <em>a</em>s, dann ist <span class="math inline">\(\beta_4\)</span> der Unterschied zwischen diesen beiden Unterschieden. Das heißt auch, dass <span class="math inline">\(\beta_4\)</span> dann signifikant von Null verschieden sein wird, wenn es eine <span style=" font-weight: bold;    color: #6BBFA6 !important;">nicht-additive Interaktion</span> zwischen den beiden Faktoren gibt.</p>
<p>An sich gibt es viele <span style=" font-weight: bold;    color: #E8793A !important;">unterschiedliche, aber gleichwertige Möglichkeiten</span>, ein lineares Modell zu repräsentieren: zum Beispiel Fig. b) vs. Fig. c). <span style=" font-weight: bold;    color: #E8793A !important;">Non-redundante Kodierungen</span> ermöglichen uns die Repräsentation auszuwählen, die wir am leichtesten zu interpretieren finden.</p>
</div>
<div id="slope-fur-numerische-pradiktoren" class="section level3">
<h3><span class="header-section-number">2.3.6</span> Slope für numerische Prädiktoren</h3>
<ul>
<li>Bisher hätte man all diese Dinge auch mit Averaging/Berechnungen von Unterschieden lösen können.
<ul>
<li>Jetzt kommen aber <span style=" font-weight: bold;    color: #E8793A !important;">kontinuierliche Kovariaten</span> dazu.</li>
<li>Hier: <span style=" font-weight: bold;    color: #E8793A !important;">Word Expectancy</span> von 0 - 1.</li>
<li>Die Expectancy für jedes Wort wurde zuvor außerhalb der Studie normiert (<a href="https://en.wikipedia.org/wiki/Cloze_test">Lückentext</a>).</li>
</ul></li>
<li>Ein Intercept kommt in der Regel trotzdem immer dazu, denn sonst würden wir davon ausgehen, dass das Outcome Null ist, wenn der Prädiktor Null ist; und das ist meistens unrealistisch.</li>
</ul>
<p>Definition von Prädiktoren für den Word-Expectancy-Effekt:</p>
<p><span class="math display">\[
\boldsymbol{x}_{1 i}=\mathbf{1}, \quad x_{2 i}=\textrm{ word expectancy on trial } i
\]</span></p>
<ul>
<li><span class="math inline">\(\beta_1\)</span> ist jetzt eine Art <span style=" font-weight: bold;    color: #E8793A !important;">Baseline</span>: Das Hirnpotenzial, das wir als Antwort auf Items <span class="math inline">\(x_{2i} = 0\)</span> erwarten, also Items die in der Normierungstask niemals geraten wurden (maximal unerwartet waren).</li>
<li><span class="math inline">\(\beta_2\)</span> schätzt, wie sehr dieses ERP sich <span style=" font-weight: bold;    color: #6BBFA6 !important;">pro Einheit</span> von Expectancy verändert.
<ul>
<li>Wenn wir uns von einer Expectancy von 0 zu einer Expectancy von 0.5 bewegen, verursacht das eine Veränderung von <span class="math inline">\(0.5 \times \beta_2\)</span> im vorhergesagten ERP.</li>
<li><span class="math inline">\(\beta_2\)</span> ist der <span style=" font-weight: bold;    color: #E8793A !important;">Slope der Regressionslinie</span>, der <span class="math inline">\(x_{2i}\)</span> mit <span class="math inline">\(y_i\)</span> verbindet.</li>
</ul></li>
</ul>
<div class="figure"><span id="fig:unnamed-chunk-6"></span>
<img src="pics/smith_a_fig2.jpg" alt="Modell mit einem kategorialen Prädiktor." width="1522" />
<p class="caption">
Figure 2.4: Modell mit einem kategorialen Prädiktor.
</p>
</div>
<ul>
<li><p>Der <span style=" font-weight: bold;    color: #E8793A !important;">positive Ausschlag</span> in der <span class="math inline">\(\beta_2\)</span>-Welle bei 300 ms bedeutet eine verstärkte Positivierung für besonders erwartete Wörter …</p>
<ul>
<li>… was im Umkehrschluss eine Negativierung für wenig erwartete Wörter bedeutet.</li>
</ul></li>
<li><p>Dieser Effekt schlägt sich in den vorhergesagten ERPs wieder: Es ist <span style=" font-weight: bold;    color: #6BBFA6 !important;">positiver für erwartete Wörter</span> (<span class="math inline">\(x_{2i} = 1\)</span>) <span style=" font-weight: bold;    color: #375B42 !important;">als für unerwartete Wörter</span> (<span class="math inline">\(x_{2i} = 0\)</span>).</p></li>
<li><p>Die Prädiktoren sind denen sehr ähnlich, die wir fürs Treatment-Coding zuvor benutzt haben:</p>
<ul>
<li>Wir haben einen <span style=" font-weight: bold;    color: #6BBFA6 !important;">Intercept-Term</span> <span class="math inline">\(x_{1i}\)</span>, dessen dazugehöriger Parameter <span class="math inline">\(\beta_1\)</span> uns eine Art <span style=" font-weight: bold;    color: #6BBFA6 !important;">Baseline</span> gibt.</li>
<li>Wir haben zusätzlich <span class="math inline">\(x_{2i}\)</span>, das <span style=" font-weight: bold;    color: #6BBFA6 !important;">Abweichungen von dieser Baseline</span> kodiert.</li>
</ul></li>
<li><p>Der Unterschied ist:</p>
<ul>
<li>Im Treatment-Coding vorhin hat der Parameter <span class="math inline">\(\beta_2\)</span> den Unterschied in der Skalp-Spannung <span style=" font-weight: bold;    color: #6BBFA6 !important;">zwischen <em>a</em>- and <em>an</em>-Stimuli</span>, in der Einheit <span class="math inline">\(\mu V\)</span>.</li>
<li>Hier misst <span class="math inline">\(\beta_2\)</span> den Unterschied in der Skalp-Spannung, der mit der <span style=" font-weight: bold;    color: #6BBFA6 !important;">Änderung von Expectancy um eine Einheit</span>, einhergeht, in der Einheit von <span class="math inline">\(\mu V\)</span> pro Einheitsänderung in Expectancy.</li>
</ul></li>
<li><p>Ist also ziemlich dasselbe wie das Unterschieds-ERP vorher, außer dass wir den Stimuli diesmal erlauben, Werte zwischen den beiden Extremen anzunehmen.</p></li>
</ul>
</div>
<div id="kombination-kategorialer-und-kontinuierlicher-pradiktoren" class="section level3">
<h3><span class="header-section-number">2.3.7</span> Kombination kategorialer und kontinuierlicher Prädiktoren</h3>
<p>Wir kombinieren die kategorialen und kontinuierlichen Prädiktoren von vorhin:</p>
<p><span class="math display">\[
\boldsymbol{x}_{1 i}=\mathbf{1} \quad \boldsymbol{x}_{2 i}=\left\{\begin{array}{ll}{\mathbf{0},} &amp; {\text { if stimulus } i \text { is a}} \\ {\mathbf{1},} &amp; {\text { if stimulus } \boldsymbol{i} \text { is an }}\end{array} \quad \boldsymbol{x}_{3 i}=\text { word expectancy on trial } i\right.
\]</span></p>
<div class="figure"><span id="fig:unnamed-chunk-7"></span>
<img src="pics/smith_a_fig3_full.jpg" alt="Modell mit einem kontinuierlichen und einem kategorialen Prädiktor." width="100%" />
<p class="caption">
Figure 2.5: Modell mit einem kontinuierlichen und einem kategorialen Prädiktor.
</p>
</div>
<p>Die resultierenden <span class="math inline">\(\beta\)</span>s haben dieselbe Interpretation wie in den vorherigen Beispielen:</p>
<ul>
<li><span class="math inline">\(\beta_1\)</span> spiegelt die vorhergesagten ERPs für <em>a</em>-Trials wider, wenn die <span style=" font-weight: bold;    color: #6BBFA6 !important;">Worterwartung Null ist</span>.</li>
<li><span class="math inline">\(\beta_2\)</span> spiegelt den Unterschied zwischen <em>an</em>-Trials und <em>a</em>-Trials wider.
<ul>
<li>Dieses Modell nimmt an, dass der über alle Trials hinweg derselbe ist.</li>
</ul></li>
<li><span class="math inline">\(\beta_3\)</span> spiegelt das vorhergesagte ERP pro Änderung von Expectancy um eine Einheit wider.</li>
</ul>
<div id="mit-interaktion" class="section level4">
<h4><span class="header-section-number">2.3.7.1</span> Mit Interaktion</h4>
<p>Für eine Interaktion müssen wir <span class="math inline">\(x_{4i} = x_{2i} \times x_{3i}\)</span> hinzufügen, und dann passiert Folgendes:</p>
<ul>
<li><span class="math inline">\(\beta_3\)</span> spiegelt den Expectancy-Effekt für <em>a</em>-Stimuli wider.</li>
<li><span class="math inline">\(\beta_4\)</span> spiegelt den <span style=" font-weight: bold;    color: #6BBFA6 !important;">Unterschied zwischen</span> dem Erwartungseffekt für <em>a</em>-Stimuli und dem Erwartungseffekt für <em>an</em>-Stimuli wider.</li>
</ul>
</div>
<div id="komplexere-falle" class="section level4">
<h4><span class="header-section-number">2.3.7.2</span> Komplexere Fälle</h4>
<ul>
<li>Manchmal gehören zu Ereignissen <span style=" font-weight: bold;    color: #6BBFA6 !important;">mehr oder andere Prädiktoren</span> als zu anderen.
<ul>
<li>Z.B. gibt es in einem Go/No-Go-Paradigma Reaktionszeiten für Go-Trials, aber nicht für No-Go-Trials</li>
</ul></li>
<li>Zwei Möglichkeiten:
<ul>
<li><ol style="list-style-type: lower-alpha">
<li>Die Trials aufteilen und getrennte Analysen für beide Sets rechnen.</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li>Wieder den “Zero-Trick” benutzen: Einfach <span style=" font-weight: bold;    color: #6BBFA6 !important;">beide Prädiktorensets in ein einziges Model packen</span>, mit folgender Regel: <span style=" font-weight: bold;    color: #6BBFA6 !important;">Immer wenn wir einen Trial haben, zu dem ein bestimmter Prädiktor nicht passt, setzen wir diesen auf Null</span>:</li>
</ol></li>
</ul></li>
</ul>
<p><span class="math display">\[
x_{1 i}=\left\{\begin{array}{ll}{1,} &amp; {\text { on } \mathrm{no}-\mathrm{go} \text { trials }} \\ {0,} &amp; {\text { on go trials }}\end{array}\right.
\]</span></p>
<p><span class="math display">\[
x_{2 i}=\left\{\begin{array}{ll}{0,} &amp; {\text { on } \mathrm{no}-\mathrm{go} \text { trials }} \\ {1,} &amp; {\text { on go trials }}\end{array}\right.
\]</span></p>
<p><span class="math display">\[
x_{3 i}=\left\{\begin{array}{cc}{0,} &amp; {\text { on no-go trials }} \\ {\mathrm{RT}_{i},} &amp; {\text { on go trials }}\end{array}\right.
\]</span></p>
<p>Auf diese Weise hat der <span class="math inline">\(\beta\)</span>-Wert des Prädiktors <span class="math inline">\(x_{3i}\)</span> keine Auswirkungen auf die Vorhersagen unseres Modells für No-Go-Trials.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="von-averaging-zur-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="kollinearitat.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": 3,
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
